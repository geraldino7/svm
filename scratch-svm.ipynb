{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch SVM Implementation From Scratch in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libaries\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "\n",
    "\tdef fit(self, data ):\n",
    "\n",
    "\t\t# Our goal is to find out w ( Direction ) and b ( Interception ) for optimial hyperplane wx+b\n",
    "\t\t# for that, we'll try various w and b values\n",
    "\n",
    "\t\tb_step_size = 2\n",
    "\t\tb_multiple = 5\n",
    "\n",
    "\t\t# finding possiblity of hyperplane in left top, right top, left bottom and right bottom axes. \n",
    "\t\taxes = [ [1,1],[-1,1],[-1,-1],[1,-1] ]\n",
    "\n",
    "\n",
    "\t\t# let's find out maximum and minimum feature value\n",
    "\n",
    "\t\tfeatures = np.concatenate((data[-1],data[1]))\n",
    "\t\tmax_feature_value = np.max(features)\n",
    "\t\tmin_feature_value = np.min(features)\n",
    "\t\tlearning_rate = max_feature_value * .001\n",
    "\n",
    "\n",
    "\t\t# Possible b values\n",
    "\t\tb_range = np.arange( -1 * (max_feature_value * b_step_size), max_feature_value * b_step_size, learning_rate * b_multiple )\n",
    "\n",
    "\t\t# this is just assumation for starting point.\n",
    "\t\tw_optimum = max_feature_value / 2\n",
    "\t\tw = np.array([w_optimum, w_optimum])\n",
    "\t\toptimized = False\n",
    "\t\thyperplane_collection = {}\n",
    "\t\twhile not optimized:\n",
    "\t\t\tfor b in b_range:\n",
    "\t\t\t\tfor section in axes:\n",
    "\t\t\t\t\tmay_be_w = w*section\n",
    "\t\t\t\t\tsuitable_hyperplane = True\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tfor one in data:\n",
    "\t\t\t\t\t\tfor feature_data in data[one]:\n",
    "\t\t\t\t\t\t\tif one*(np.dot(may_be_w,feature_data) +b) < 1:\n",
    "\t\t\t\t\t\t\t\t# if any feature data is within the hyperplane margin, that's not the suitable hyperplane.\n",
    "\t\t\t\t\t\t\t\tsuitable_hyperplane = False\n",
    "\n",
    "\t\t\t\t\tif suitable_hyperplane:\n",
    "\n",
    "\t\t\t\t\t\t# Calculate length of hyperplane direction\n",
    "\t\t\t\t\t\thyperplane_norm = np.linalg.norm(may_be_w) # || w ||\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t# we need to keep track of these possible hyperplane. later, we'll choose which has minimum hyperplace norm as optimizal hyperplane.\n",
    "\t\t\t\t\t\thyperplane_collection[ hyperplane_norm ] = [may_be_w,b] # Save w and b\t\n",
    "\n",
    "\t\t\tif w[0] < 0:\n",
    "\t\t\t\toptimized = True\n",
    "\t\t\telse:\n",
    "\t\t\t\tw = w-learning_rate\t\n",
    "\n",
    "\t\t# now sort by norm length\n",
    "\t\tnorms = sorted([n for n in hyperplane_collection])\n",
    "\t\tminimum_norm = norms[0]\n",
    "\n",
    "\t\t# This one is optimizal hyperplane\n",
    "\t\toptimal_hyperplane = hyperplane_collection[minimum_norm]\n",
    "\n",
    "\t\tself.w = optimal_hyperplane[0]\n",
    "\t\tself.b = optimal_hyperplane[1]\n",
    "\t\t\n",
    "\t#fit(data)\n",
    "\n",
    "\tdef calculate_y(self,x,w,b,v):\n",
    "\t\t# w.x+b = v\n",
    "\t\t# w0x0 + w1x1 + b = v\n",
    "\t\t# x1 = (v - w0x0 - b)/w1\n",
    "\t\ty = (v - w[0] * x - b) / w[1]\n",
    "\t\treturn y\n",
    "\n",
    "\tdef show_hyperplane(self,data):\n",
    "\n",
    "\t\timport matplotlib.pyplot as plt\n",
    "\t\t\n",
    "\t\tw = self.w\n",
    "\t\tb = self.b\n",
    "\n",
    "\t\tfeatures = np.concatenate((data[-1],data[1]))\n",
    "\t\t\n",
    "\t\tx1 = np.max(features)\n",
    "\t\ty1 = self.calculate_y(x1, w, b, 0)\n",
    "\t\t\n",
    "\t\tx2 = np.min(features)\n",
    "\t\ty2 = self.calculate_y(x2, w, b, 0)\n",
    "\t\t\n",
    "\t\tfigure = plt.figure()\n",
    "\t\tax = figure.add_subplot(1,1,1)\n",
    "\n",
    "\t\tplt.scatter(data[-1][:,0],data[-1][:,1],marker=\"o\", c=\"r\")\n",
    "\t\tplt.scatter(data[1][:,0],data[1][:,1],marker=\"+\", c=\"g\")\n",
    "\t\t\n",
    "\t\t# This line should clearly separate male and female dataset\n",
    "\t\tax.plot([x1,x2],[y1,y2],'k')\n",
    "\t\t\n",
    "\t\tplt.show()\n",
    "\t\t\n",
    "\n",
    "\tdef predict(self,features):\n",
    "\t\tw = self.w\n",
    "\t\tb = self.b\n",
    "\t\tclassification = np.sign(np.dot(np.array(features),w) + b)\n",
    "\t\treturn classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data - (weight (kg), Height (cm), gender)\n",
    "sample_data = np.array([\n",
    "\t[70,175,'male'],\n",
    "\t[60,140,'female'],\n",
    "\t[80,185,'male'],\n",
    "\t[75,180,'male'],\n",
    "\t[65,150,'female'],\n",
    "\t[70,155,'female'],\n",
    "\t[75,160,'female'],\n",
    "\t[85,195,'male'],\n",
    "\t[55,170,'female'],\n",
    "\t[65,175,'female'],\n",
    "\t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sample_data[:,:2].astype('float')\n",
    "target = sample_data[:,2]\n",
    "\n",
    "# Assign -1 to female and +1 to male\n",
    "plusone = []\n",
    "minusone = []\n",
    "\n",
    "for i,gender in enumerate(target):\n",
    "\n",
    "\tif gender == 'male':\n",
    "\t\tplusone.append(features[i])\n",
    "\telse:\n",
    "\t\tminusone.append(features[i])\n",
    "\n",
    "data = { -1: np.array(minusone), 1: np.array(plusone) }\n",
    "classify = { -1: 'Female', 1: 'Male' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target - What is gender if weight is 50kg and height is 172cm ?\n",
    "guess = [[50,172]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup SVM Model\n",
    "model = SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "prediction = model.predict(guess).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender is Female\n"
     ]
    }
   ],
   "source": [
    "print(\"Gender is %s\" %(classify[prediction[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show optimial hyperplane. \n",
    "model.show_hyperplane(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
